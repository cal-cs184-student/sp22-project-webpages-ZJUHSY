<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_xsatx84mgbpj-3>li{counter-increment:lst-ctn-kix_xsatx84mgbpj-3}.lst-kix_sow1giazn8fk-7>li:before{content:"\0025cb  "}.lst-kix_sow1giazn8fk-6>li:before{content:"\0025cf  "}.lst-kix_sow1giazn8fk-8>li:before{content:"\0025a0  "}.lst-kix_sow1giazn8fk-5>li:before{content:"\0025a0  "}ol.lst-kix_xsatx84mgbpj-5.start{counter-reset:lst-ctn-kix_xsatx84mgbpj-5 0}.lst-kix_xsatx84mgbpj-4>li:before{content:"" counter(lst-ctn-kix_xsatx84mgbpj-4,lower-latin) ". "}.lst-kix_xsatx84mgbpj-5>li:before{content:"" counter(lst-ctn-kix_xsatx84mgbpj-5,lower-roman) ". "}.lst-kix_sow1giazn8fk-0>li:before{content:"\0025cf  "}.lst-kix_xsatx84mgbpj-6>li:before{content:"" counter(lst-ctn-kix_xsatx84mgbpj-6,decimal) ". "}.lst-kix_sow1giazn8fk-1>li:before{content:"\0025cb  "}.lst-kix_xsatx84mgbpj-4>li{counter-increment:lst-ctn-kix_xsatx84mgbpj-4}ol.lst-kix_xsatx84mgbpj-2.start{counter-reset:lst-ctn-kix_xsatx84mgbpj-2 0}.lst-kix_xsatx84mgbpj-8>li:before{content:"" counter(lst-ctn-kix_xsatx84mgbpj-8,lower-roman) ". "}.lst-kix_sow1giazn8fk-3>li:before{content:"\0025cf  "}.lst-kix_xsatx84mgbpj-7>li:before{content:"" counter(lst-ctn-kix_xsatx84mgbpj-7,lower-latin) ". "}.lst-kix_sow1giazn8fk-2>li:before{content:"\0025a0  "}.lst-kix_sow1giazn8fk-4>li:before{content:"\0025cb  "}ol.lst-kix_xsatx84mgbpj-6.start{counter-reset:lst-ctn-kix_xsatx84mgbpj-6 0}ul.lst-kix_sow1giazn8fk-7{list-style-type:none}ul.lst-kix_sow1giazn8fk-8{list-style-type:none}ul.lst-kix_sow1giazn8fk-5{list-style-type:none}ul.lst-kix_sow1giazn8fk-6{list-style-type:none}ul.lst-kix_sow1giazn8fk-3{list-style-type:none}ul.lst-kix_sow1giazn8fk-4{list-style-type:none}ul.lst-kix_sow1giazn8fk-1{list-style-type:none}ul.lst-kix_sow1giazn8fk-2{list-style-type:none}.lst-kix_xsatx84mgbpj-3>li:before{content:"" counter(lst-ctn-kix_xsatx84mgbpj-3,decimal) ". "}.lst-kix_xsatx84mgbpj-2>li:before{content:"" counter(lst-ctn-kix_xsatx84mgbpj-2,lower-roman) ". "}ol.lst-kix_xsatx84mgbpj-3.start{counter-reset:lst-ctn-kix_xsatx84mgbpj-3 0}.lst-kix_xsatx84mgbpj-8>li{counter-increment:lst-ctn-kix_xsatx84mgbpj-8}.lst-kix_xsatx84mgbpj-0>li:before{content:"" counter(lst-ctn-kix_xsatx84mgbpj-0,decimal) ". "}.lst-kix_xsatx84mgbpj-1>li:before{content:"" counter(lst-ctn-kix_xsatx84mgbpj-1,lower-latin) ". "}.lst-kix_xsatx84mgbpj-5>li{counter-increment:lst-ctn-kix_xsatx84mgbpj-5}.lst-kix_xsatx84mgbpj-2>li{counter-increment:lst-ctn-kix_xsatx84mgbpj-2}ol.lst-kix_xsatx84mgbpj-7.start{counter-reset:lst-ctn-kix_xsatx84mgbpj-7 0}.lst-kix_xsatx84mgbpj-0>li{counter-increment:lst-ctn-kix_xsatx84mgbpj-0}ol.lst-kix_xsatx84mgbpj-0.start{counter-reset:lst-ctn-kix_xsatx84mgbpj-0 0}.lst-kix_xsatx84mgbpj-6>li{counter-increment:lst-ctn-kix_xsatx84mgbpj-6}ul.lst-kix_sow1giazn8fk-0{list-style-type:none}ol.lst-kix_xsatx84mgbpj-4.start{counter-reset:lst-ctn-kix_xsatx84mgbpj-4 0}.lst-kix_xsatx84mgbpj-7>li{counter-increment:lst-ctn-kix_xsatx84mgbpj-7}ol.lst-kix_xsatx84mgbpj-1.start{counter-reset:lst-ctn-kix_xsatx84mgbpj-1 0}ol.lst-kix_xsatx84mgbpj-8.start{counter-reset:lst-ctn-kix_xsatx84mgbpj-8 0}.lst-kix_xsatx84mgbpj-1>li{counter-increment:lst-ctn-kix_xsatx84mgbpj-1}ol.lst-kix_xsatx84mgbpj-2{list-style-type:none}ol.lst-kix_xsatx84mgbpj-1{list-style-type:none}ol.lst-kix_xsatx84mgbpj-0{list-style-type:none}ol.lst-kix_xsatx84mgbpj-8{list-style-type:none}ol.lst-kix_xsatx84mgbpj-7{list-style-type:none}ol.lst-kix_xsatx84mgbpj-6{list-style-type:none}ol.lst-kix_xsatx84mgbpj-5{list-style-type:none}ol.lst-kix_xsatx84mgbpj-4{list-style-type:none}ol.lst-kix_xsatx84mgbpj-3{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c10{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left;height:20pt}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c15{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:26pt;font-family:"Arial";font-style:normal}.c11{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Arial";font-style:normal}.c12{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c8{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:center}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c7{padding-top:0pt;padding-bottom:3pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c6{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c5{color:#333333;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c17{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c24{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c4{font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c19{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c18{background-color:#ffffff;max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c16{color:inherit;text-decoration:inherit}.c22{color:#ffffff;font-size:9pt}.c20{font-weight:700}.c13{height:16pt}.c23{height:20pt}.c3{color:#0e101a}.c9{font-style:italic}.c21{margin-left:180pt}.c2{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c18"><div><p class="c1 c2"><span class="c0"></span></p></div><p class="c7 title" id="h.m8ti83yvzib"><span class="c15">Project 1: Rasterizer</span></p><p class="c1 c2"><span class="c0"></span></p><h1 class="c12" id="h.17apm9en0zyu"><span class="c11">Project Overview</span></h1><p class="c1"><span class="c0">Overall, we build a rasterizer, which is a combination of projection, filtering, and sampling, in other words. We start by implementing simple triangle rasterization, a sampling method that frames the pixels by triangle meshes.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Then we replenish our implementation by incorporating functions such as anti-aliasing by super-sampling to smooth the high-frequency part of the frame buffer. In part 4, we also implement barycentric linear interpolation, a more accurate way of representing each pixel&rsquo;s color than super-sampling. </span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Besides, we execute transformations in Part3, enabling dynamic features such as scaling, rotating, and translating. </span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">We complete our implementation in parts 5 and 6 by adding texture mapping functions. Our rasterizer can finally switch the sampling texels and mipmap levels, enabling more non-linear transformation/mappings to create surprising visual effects!</span></p><h2 class="c6" id="h.vq8n8vd53suz"><span class="c14">Interesting Thoughts</span></h2><p class="c1"><span class="c0">Through this project, I can see the power of transformations to create different beauties. Besides, implementing super-sampling and barycentric coordinates and seeing their actual impact on images makes a more profound understanding of those theories behind. </span></p><p class="c1 c2"><span class="c0"></span></p><h1 class="c12" id="h.dxspccwd077b"><span class="c11">Task1</span></h1><h2 class="c6" id="h.xomb2kw95az0"><span class="c14">Algorithm</span></h2><p class="c1"><span class="c0">In this part of the implementation, we use the three vertices of the triangle to calculate the bounding box of the algorithm. We utilize minimum and maximum to calculate the bounding box&rsquo;s boundary to be more specific. Also, our algorithm includes the points lying in the border of the triangle meshes. (No OpenGL rules applied). </span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">To test whether the point is inside the triangle area, we implement the algorithm proposed in the lecture, which calculates three-line tests and checks its consistency on positivity or negativity. This will work regardless of the winding order of the triangle&#39;s vertices. </span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">The above implementation is equivalent to checking every point in the bounding box formed by the three vertices.</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c6" id="h.lgvn8d7hmtnl"><span class="c14">Screenshot</span></h2><p class="c1"><span class="c0">Below is the screenshot of task 1.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 330.67px;"><img alt="" src="images/image13.png" style="width: 601.70px; height: 330.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c20 c24">Task1 Screenshot</span></p><p class="c1 c2 c21"><span class="c24 c20"></span></p><h1 class="c10" id="h.i56jxppth42l"><span class="c11"></span></h1><h1 class="c12" id="h.d6occi5phg4t"><span class="c11">Task2</span></h1><h2 class="c6" id="h.97673jbq8369"><span class="c14">Data Structure</span></h2><p class="c1"><span class="c3">In all of the tasks, we use the data structure </span><span class="c3 c9">rgb_framebuffer_target</span><span class="c3">, which is an array of characters. Each element of </span><span class="c3 c9">rgb_framebuffer_target </span><span class="c4 c3">stores a pointer that points to a single color of each pixel in the framebuffer, the target used to draw the graph. </span></p><p class="c1 c2"><span class="c3 c4"></span></p><p class="c1"><span class="c3">In task 2, however, we need an extra data structure, </span><span class="c3 c9">sample_buffer</span><span class="c3">, a vector of the color object. The size is dependent on the original pixel size, and the super-sample rate users choose. </span></p><p class="c1"><span class="c22">rgb_framebuffer_targe</span></p><h2 class="c6" id="h.tsbwozebk3jn"><span class="c14">Algorithm</span></h2><p class="c1"><span class="c3">Below is the rasterization pipeline. Whenever the sample rate is set, we first need to resize our </span><span class="c3 c9">sample_buffer </span><span class="c3">data structure. (in both </span><span class="c20 c3 c9">set_sample_rate</span><span class="c3">&nbsp;and </span><span class="c20 c3 c9">set_framebuffer_target </span><span class="c4 c3">function).</span></p><p class="c1 c2"><span class="c4 c3"></span></p><p class="c1"><span class="c3">Then we implement the core part of super-sampling. Based on task 1, in the </span><span class="c3 c9 c20">rasterize_triangle </span><span class="c4 c3">function, we implement two extra inner loops inside the outer two loops, which iterate through the original bounding box. The two inner loops walk through the &ldquo;super pixels&rdquo; inside each original pixel. The coordinates of the &ldquo;super pixels&rdquo; are dependent on the sample rate. Therefore, we should calculate inside or outside the triangle before filling the colors for the &ldquo;super pixels&rdquo; based on previous functions. </span></p><p class="c1 c2"><span class="c4 c3"></span></p><p class="c1"><span class="c3">Finally, we need to transform the super-sampling color into the frame buffer. In the </span><span class="c20 c3 c9">resolve_to_framebuffer</span><span class="c3">&nbsp;function, we average the color values of every super pixel inside an original pixel box. </span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c6" id="h.w97hbjybqza4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 535.50px; height: 296.00px;"><img alt="" src="images/image7.png" style="width: 535.50px; height: 296.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c14">Experiment</span></h2><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c17"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; SuperSampling Rate=1</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 536.00px; height: 339.00px;"><img alt="" src="images/image12.png" style="width: 536.00px; height: 339.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c17"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c17"><span class="c0">SuperSampling Rate=4</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 536.00px; height: 339.00px;"><img alt="" src="images/image11.png" style="width: 536.00px; height: 339.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><h1 class="c10" id="h.lc6xjs77rscv"><span class="c11"></span></h1><h1 class="c10" id="h.mhemjs45iy44"><span class="c11"></span></h1><h1 class="c12" id="h.6b7j7nww5ept"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></h1><h1 class="c8 c23" id="h.ner2d6gmlgom"><span class="c0"></span></h1><h1 class="c8" id="h.od0rr76vyi15"><span class="c0">SuperSampling Rate=16</span></h1><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">From the three figures above, we can see that our supersampling algorithm works well. We placed our pixel inspector at the edge of the red triangle in the middle. Increasing the sample rate from 1 to 16 we can see the anti-aliasing effects on the edge from the inspector. </span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">While its edge is skinny and shows jaggies when sample rate is 1(no super sampling), its edge is blurred when sampling rate is increased. </span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Those can be explained by the inner principles of anti-aliasing. We filter out the high frequency part, in this case, the edge, of the original image by averaging its value from its neighborhood. This smoothing kernel operation is equivalent to filtering out high frequency before sampling.</span></p><p class="c1 c2"><span class="c0"></span></p><h1 class="c12" id="h.ffy0tegg8t2y"><span class="c11">Task3</span></h1><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 450.67px;"><img alt="" src="images/image8.png" style="width: 601.70px; height: 450.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c0">Description: A person is praying sincerely.</span></p><h1 class="c12" id="h.vzz355qga6li"><span class="c11">Task4</span></h1><h2 class="c6" id="h.6qep6l7tm9bo"><span class="c14">Explanations</span></h2><p class="c1"><span class="c0">The barycentric coordinate is a linear interpolation of a point&rsquo;s pixel value. Like the supersampling method, it can smooth the varying values across an object. However, unlike the supersampling method, it is a weighted smoother and smoother than supersampling. (Not only rub the most high-frequency part). The screenshot below demonstrates the barycentric coordinates&rsquo; effect. We can see the boundary between red and green yellow turns dark brown!</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 439.53px; height: 266.33px;"><img alt="" src="images/image5.png" style="width: 439.53px; height: 266.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c6 c13" id="h.wahs0qc8aijg"><span class="c14"></span></h2><h2 class="c6 c13" id="h.z82nq9k7teae"><span class="c14"></span></h2><h2 class="c6" id="h.fnauwyfoqj4d"><span class="c14">Screenshot</span></h2><p class="c1"><span class="c0">Below is the screenshot of ./svg/basic/test7.svg.</span></p><h1 class="c10" id="h.peb2t8v2yi4p"><span class="c11"></span></h1><h1 class="c12" id="h.kni6f91jnatw"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 416.00px;"><img alt="" src="images/image1.png" style="width: 601.70px; height: 416.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></h1><h1 class="c10" id="h.om92ykh4ckw2"><span class="c11"></span></h1><h1 class="c10" id="h.mx1jykki24m"><span class="c11"></span></h1><h1 class="c10" id="h.sy1fjqlmmzl1"><span class="c11"></span></h1><h1 class="c10" id="h.7n96ucus4ok3"><span class="c11"></span></h1><h1 class="c10" id="h.adbbt2any20n"><span class="c11"></span></h1><h1 class="c10" id="h.z2whak9letuv"><span class="c11"></span></h1><h1 class="c12" id="h.ajhv0jspn2bm"><span class="c11">Task5</span></h1><p class="c1"><span class="c0">In this task, we implemented texture mapping through pixel sampling and sampled on full-resolution texture images by two different methods: nearest neighbor and bilinear interpolation.</span></p><p class="c1"><span class="c0">In the process of texture mapping, we use the U-V coordinate system, which is a coordinate system defined on the two-dimensional texture, so that any point on the surface can be represented by (U, V), similar to the rectangular coordinates represented by (x, y), where you represents the abscissa of the texture and V represents the ordinate of the surface. Because different textures have different sizes, the power coordinates you and V are not directly related to the size and shape of the texture. For any texture, the range of u and V is [0,1], UV(0,0) represents the lower left corner of the texture, UV(0.5,0.5) represents the texture center, and UV(1,1) represents the upper right corner of the texture.</span></p><p class="c1"><span class="c0">In the actual texture mapping, multiple original pixels will correspond to the same texture pixel because the texture size is different from the mapping size, making the texture mapping blurred. To solve this problem, we use the above two methods for mapping.</span></p><p class="c1"><span class="c0">For nearest neighbor sampling, we use the nearest pixel to sample. It is a naive way to map texture. The results are as follows:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 465.33px;"><img alt="" src="images/image2.png" style="width: 601.70px; height: 465.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span>For bilinear interpolation, we use bilinear sampling, which requires us to use functions floor() and ceil() to get four nearest samples around the texture pixel point. Through these four points, we can interpolate in the direction of a horizontal axis and vertical axis respectively by lerp function. The results are as follows:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 453.33px;"><img alt="" src="images/image6.png" style="width: 601.70px; height: 453.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">From the result, We can see that the result of bilinear interpolation is less blurred than that of the nearest neighbor. This is because, through bilinear interpolation, the color of texture pixels will be related to the color of the surrounding four points, not just their original color. The blur effect will be weakened through linear change.</span></p><p class="c1 c2"><span class="c5"></span></p><h1 class="c12" id="h.odhf20su7jrh"><span class="c11">Task6</span></h1><p class="c1"><span class="c0">In this task, we conduct mipmap level sampling based on task5. Since Task5 sampled on the 0th mipmap level, we will realize the nearest appropriate mipmap level and linear continuous mipmap level.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">In task5, we can get the color value of any point on the texture through the nearest neighbor and bilinear interpolation. These methods belong to Point Query. However, none of them can effectively eliminate the molar texture. Therefore, we need to query the average value through the Range Query and the texture pixels in a certain range. A mipmap is used to solve this problem. Mipmap generates a series of corresponding textures for a texture, and the resolution of the generated surface decreases gradually. For example, layer 0 is full resolution, and the last layer has only one pixel. If the size of each layer is half of that of the previous layer, a total of logN layers will be generated. Therefore, we can significantly save our mapping time and effectively reduce the molar texture by developing a good mipmap for a range query.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">At first, I needed to complete getlevel () as the helper function to get the current level. To achieve this, it is necessary to calculate the derivatives of u and v to x and y, respectively.</span></p><p class="c1"><span class="c0">And level can be calculated by the following expression. </span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 97.33px;"><img alt="" src="images/image9.png" style="width: 601.70px; height: 97.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c0">We can also use floor() to get lower level, use ceil() to get upper level, and round() to get the nearest level. </span></p><p class="c1"><span class="c0">For the 0th mipmap level, we need to call the functions finished in Task5 with 0 levels, so the description will not be repeated here. The results are as follows:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 452.00px;"><img alt="" src="images/image10.png" style="width: 601.70px; height: 452.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c0">For the nearest appropriate mipmap level, we first need to obtain the current level and then obtain the closest level generated by mipmap according to the specific level value. Then pass this level into the nearest and binary function in the task5 to get the result. The results are as follows:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 450.67px;"><img alt="" src="images/image4.png" style="width: 601.70px; height: 450.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c0">We used trilinear sampling described in the lecture for the linear continuous mipmap level. Trilinear interpolation requires us to obtain the upper level and lower level of the current level and then bring the two levels into the sample function for differential superposition. Each layer is linear, and the upper and lower layers are also a linear combination. The results are as follows:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 446.67px;"><img alt="" src="images/image3.png" style="width: 601.70px; height: 446.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h1 class="c12" id="h.crwo3bk2s1o8"><span class="c11">Webpage Link</span></h1><p class="c1"><span>Our web page is hosted at </span><span class="c19"><a class="c16" href="https://www.google.com/url?q=https://cal-cs184-student.github.io/sp22-project-webpages-ZJUHSY/proj1/index.html&amp;sa=D&amp;source=editors&amp;ust=1645002113988781&amp;usg=AOvVaw17r01WbHXE99T9ivPZt4DX">Project1</a></span><span>.</span></p><div><p class="c1 c2"><span class="c0"></span></p></div></body></html>